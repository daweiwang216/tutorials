{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e96492c3-2ba2-46cb-95d9-c319e03fc2e5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### This is the accompanying code for a tutorial on Medium. Click below to view the tutorial. \n",
    "**[Tutorial in English](https://medium.com/tutorial-by-winston-wang/beginners-guide-to-fine-tuning-models-using-mlx-on-apple-silicon-1a21ebb70aed), [简体中文](https://medium.com/tutorial-by-winston-wang/在apple-silicon上使用mlx对模型进行微调的新手教程-f5f9959d8961)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7912e94d",
   "metadata": {},
   "source": [
    "## Load the model from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa8b084",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "access_token = 'hf_************' # paste your token here\n",
    "login(access_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276a972e-a0a2-4cb2-a0f6-8b72faf503dd",
   "metadata": {},
   "source": [
    "**When loading the model, we can load the tokenizer together, making subsequent operations more convenient:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab35553f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlx_lm import generate, load\n",
    "\n",
    "model, tokenizer = load(\"google/gemma-2-2b-it\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7346b0-9b80-4e0b-9208-98d8b1b25eb7",
   "metadata": {},
   "source": [
    "**Edit a prompt to ask the model a question and test the model loading.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae75e607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "Prompt: <bos><start_of_turn>user\n",
      "What is under-fitting and overfitting in machine learning?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "\n",
      "Let's break down underfitting and overfitting in machine learning:\n",
      "\n",
      "**Understanding the Basics**\n",
      "\n",
      "* **Machine Learning:**  Machine learning is a type of artificial intelligence (AI) where computers learn from data without explicit programming. They use algorithms to identify patterns and make predictions.\n",
      "* **Model:** A model is a mathematical representation of the relationship between input data and desired output. Think of it as a simplified version of the real-world phenomenon you're trying to understand.\n",
      "\n",
      "**\n",
      "==========\n",
      "Prompt: 22 tokens, 72.806 tokens-per-sec\n",
      "Generation: 100 tokens, 12.132 tokens-per-sec\n",
      "Peak memory: 7.535 GB\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What is under-fitting and overfitting in machine learning?\"\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "\n",
    "response = generate(model, tokenizer, prompt=prompt, verbose=True, max_tokens = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02db27a8-e91b-4805-a98f-2bf2eb00fdda",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d48b9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"win-wang/Machine_Learning_QA_Collection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ac5667-8989-4539-a4d2-ae84998f805a",
   "metadata": {},
   "source": [
    "**Convert the dataset to DataFrame format and check it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a863fddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;start_of_turn&gt;user\\n    I am solving a system...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;start_of_turn&gt;user\\n    I get a gtk-WARNING w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;start_of_turn&gt;user\\n    I don't really like w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;start_of_turn&gt;user\\n    I am having trouble f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;start_of_turn&gt;user\\n    How do Recurrent Neur...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  <start_of_turn>user\\n    I am solving a system...\n",
       "1  <start_of_turn>user\\n    I get a gtk-WARNING w...\n",
       "2  <start_of_turn>user\\n    I don't really like w...\n",
       "3  <start_of_turn>user\\n    I am having trouble f...\n",
       "4  <start_of_turn>user\\n    How do Recurrent Neur..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_set = pd.DataFrame(ds[\"train\"])\n",
    "dev_set = pd.DataFrame(ds[\"validation\"])\n",
    "test_set = pd.DataFrame(ds[\"test\"])\n",
    "\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfd822e-7f5f-4259-b9de-93e9db4fe32b",
   "metadata": {},
   "source": [
    "**Convert datasets into lists for MLX**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36fc46e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(dataset):\n",
    "    return dataset[\"text\"].tolist()\n",
    "    \n",
    "train_set, dev_set, test_set = map(preprocess, (train_set, dev_set, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24299e1b-18ec-4b6d-8208-eb1a114ca3a1",
   "metadata": {},
   "source": [
    "## Model fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d597db82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mlx.optimizers as optim\n",
    "from mlx.utils import tree_flatten\n",
    "from mlx_lm import load, generate\n",
    "from mlx_lm.tuner import train, TrainingArgs \n",
    "from mlx_lm.tuner import linear_to_lora_layers\n",
    "from pathlib import Path\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c5b0fd-f037-4514-a87e-cb73b6581a97",
   "metadata": {},
   "source": [
    "**Create a directory to save the adapter configuration and weights.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d08f92d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter_path = Path(\"adapters\")\n",
    "adapter_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4e517c-2531-4427-abcd-bfee44102a8a",
   "metadata": {},
   "source": [
    "**Set the LoRA parameters and Save the LoRA configuration to the adapter path.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53d0658e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = {\n",
    " \"lora_layers\": 8,\n",
    " \"lora_parameters\": {\n",
    "    \"rank\": 8,\n",
    "    \"scale\": 20.0,\n",
    "    \"dropout\": 0.0,\n",
    "}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44f5436e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(adapter_path / \"adapter_config.json\", \"w\") as fid:\n",
    "    json.dump(lora_config, fid, indent=4)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa1496d-a52a-47bd-bbf4-b07dd3fb4136",
   "metadata": {},
   "source": [
    "**Set the training parameters.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4eb0940f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArgs(\n",
    "    adapter_file=adapter_path / \"adapters.safetensors\",\n",
    "    iters=200,\n",
    "    steps_per_eval=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65aa27ce-8dcf-4217-a3b5-aafac15ed4b3",
   "metadata": {},
   "source": [
    "**Freeze the base model, Convert the linear layers to LoRA layers, and Check the trainable model parameters.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6af3823",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (model): GemmaModel(\n",
       "    (embed_tokens): Embedding(256000, 2304)\n",
       "    (layers.0): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): Linear(input_dims=2304, output_dims=2048, bias=False)\n",
       "        (k_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (v_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (o_proj): Linear(input_dims=2048, output_dims=2304, bias=False)\n",
       "        (rope): RoPE(256, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "        (down_proj): Linear(input_dims=9216, output_dims=2304, bias=False)\n",
       "        (up_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "    )\n",
       "    (layers.1): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): Linear(input_dims=2304, output_dims=2048, bias=False)\n",
       "        (k_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (v_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (o_proj): Linear(input_dims=2048, output_dims=2304, bias=False)\n",
       "        (rope): RoPE(256, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "        (down_proj): Linear(input_dims=9216, output_dims=2304, bias=False)\n",
       "        (up_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "    )\n",
       "    (layers.2): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): Linear(input_dims=2304, output_dims=2048, bias=False)\n",
       "        (k_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (v_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (o_proj): Linear(input_dims=2048, output_dims=2304, bias=False)\n",
       "        (rope): RoPE(256, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "        (down_proj): Linear(input_dims=9216, output_dims=2304, bias=False)\n",
       "        (up_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "    )\n",
       "    (layers.3): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): Linear(input_dims=2304, output_dims=2048, bias=False)\n",
       "        (k_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (v_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (o_proj): Linear(input_dims=2048, output_dims=2304, bias=False)\n",
       "        (rope): RoPE(256, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "        (down_proj): Linear(input_dims=9216, output_dims=2304, bias=False)\n",
       "        (up_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "    )\n",
       "    (layers.4): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): Linear(input_dims=2304, output_dims=2048, bias=False)\n",
       "        (k_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (v_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (o_proj): Linear(input_dims=2048, output_dims=2304, bias=False)\n",
       "        (rope): RoPE(256, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "        (down_proj): Linear(input_dims=9216, output_dims=2304, bias=False)\n",
       "        (up_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "    )\n",
       "    (layers.5): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): Linear(input_dims=2304, output_dims=2048, bias=False)\n",
       "        (k_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (v_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (o_proj): Linear(input_dims=2048, output_dims=2304, bias=False)\n",
       "        (rope): RoPE(256, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "        (down_proj): Linear(input_dims=9216, output_dims=2304, bias=False)\n",
       "        (up_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "    )\n",
       "    (layers.6): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): Linear(input_dims=2304, output_dims=2048, bias=False)\n",
       "        (k_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (v_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (o_proj): Linear(input_dims=2048, output_dims=2304, bias=False)\n",
       "        (rope): RoPE(256, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "        (down_proj): Linear(input_dims=9216, output_dims=2304, bias=False)\n",
       "        (up_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "    )\n",
       "    (layers.7): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): Linear(input_dims=2304, output_dims=2048, bias=False)\n",
       "        (k_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (v_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (o_proj): Linear(input_dims=2048, output_dims=2304, bias=False)\n",
       "        (rope): RoPE(256, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "        (down_proj): Linear(input_dims=9216, output_dims=2304, bias=False)\n",
       "        (up_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "    )\n",
       "    (layers.8): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): Linear(input_dims=2304, output_dims=2048, bias=False)\n",
       "        (k_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (v_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (o_proj): Linear(input_dims=2048, output_dims=2304, bias=False)\n",
       "        (rope): RoPE(256, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "        (down_proj): Linear(input_dims=9216, output_dims=2304, bias=False)\n",
       "        (up_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "    )\n",
       "    (layers.9): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): Linear(input_dims=2304, output_dims=2048, bias=False)\n",
       "        (k_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (v_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (o_proj): Linear(input_dims=2048, output_dims=2304, bias=False)\n",
       "        (rope): RoPE(256, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "        (down_proj): Linear(input_dims=9216, output_dims=2304, bias=False)\n",
       "        (up_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "    )\n",
       "    (layers.10): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): Linear(input_dims=2304, output_dims=2048, bias=False)\n",
       "        (k_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (v_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (o_proj): Linear(input_dims=2048, output_dims=2304, bias=False)\n",
       "        (rope): RoPE(256, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "        (down_proj): Linear(input_dims=9216, output_dims=2304, bias=False)\n",
       "        (up_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "    )\n",
       "    (layers.11): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): Linear(input_dims=2304, output_dims=2048, bias=False)\n",
       "        (k_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (v_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (o_proj): Linear(input_dims=2048, output_dims=2304, bias=False)\n",
       "        (rope): RoPE(256, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "        (down_proj): Linear(input_dims=9216, output_dims=2304, bias=False)\n",
       "        (up_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "    )\n",
       "    (layers.12): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): Linear(input_dims=2304, output_dims=2048, bias=False)\n",
       "        (k_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (v_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (o_proj): Linear(input_dims=2048, output_dims=2304, bias=False)\n",
       "        (rope): RoPE(256, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "        (down_proj): Linear(input_dims=9216, output_dims=2304, bias=False)\n",
       "        (up_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "    )\n",
       "    (layers.13): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): Linear(input_dims=2304, output_dims=2048, bias=False)\n",
       "        (k_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (v_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (o_proj): Linear(input_dims=2048, output_dims=2304, bias=False)\n",
       "        (rope): RoPE(256, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "        (down_proj): Linear(input_dims=9216, output_dims=2304, bias=False)\n",
       "        (up_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "    )\n",
       "    (layers.14): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): Linear(input_dims=2304, output_dims=2048, bias=False)\n",
       "        (k_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (v_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (o_proj): Linear(input_dims=2048, output_dims=2304, bias=False)\n",
       "        (rope): RoPE(256, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "        (down_proj): Linear(input_dims=9216, output_dims=2304, bias=False)\n",
       "        (up_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "    )\n",
       "    (layers.15): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): Linear(input_dims=2304, output_dims=2048, bias=False)\n",
       "        (k_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (v_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (o_proj): Linear(input_dims=2048, output_dims=2304, bias=False)\n",
       "        (rope): RoPE(256, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "        (down_proj): Linear(input_dims=9216, output_dims=2304, bias=False)\n",
       "        (up_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "    )\n",
       "    (layers.16): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): Linear(input_dims=2304, output_dims=2048, bias=False)\n",
       "        (k_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (v_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (o_proj): Linear(input_dims=2048, output_dims=2304, bias=False)\n",
       "        (rope): RoPE(256, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "        (down_proj): Linear(input_dims=9216, output_dims=2304, bias=False)\n",
       "        (up_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "    )\n",
       "    (layers.17): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): Linear(input_dims=2304, output_dims=2048, bias=False)\n",
       "        (k_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (v_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (o_proj): Linear(input_dims=2048, output_dims=2304, bias=False)\n",
       "        (rope): RoPE(256, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "        (down_proj): Linear(input_dims=9216, output_dims=2304, bias=False)\n",
       "        (up_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "    )\n",
       "    (layers.18): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): Linear(input_dims=2304, output_dims=2048, bias=False)\n",
       "        (k_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (v_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (o_proj): Linear(input_dims=2048, output_dims=2304, bias=False)\n",
       "        (rope): RoPE(256, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "        (down_proj): Linear(input_dims=9216, output_dims=2304, bias=False)\n",
       "        (up_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "    )\n",
       "    (layers.19): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): Linear(input_dims=2304, output_dims=2048, bias=False)\n",
       "        (k_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (v_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (o_proj): Linear(input_dims=2048, output_dims=2304, bias=False)\n",
       "        (rope): RoPE(256, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "        (down_proj): Linear(input_dims=9216, output_dims=2304, bias=False)\n",
       "        (up_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "    )\n",
       "    (layers.20): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): Linear(input_dims=2304, output_dims=2048, bias=False)\n",
       "        (k_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (v_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (o_proj): Linear(input_dims=2048, output_dims=2304, bias=False)\n",
       "        (rope): RoPE(256, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "        (down_proj): Linear(input_dims=9216, output_dims=2304, bias=False)\n",
       "        (up_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "    )\n",
       "    (layers.21): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): Linear(input_dims=2304, output_dims=2048, bias=False)\n",
       "        (k_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (v_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (o_proj): Linear(input_dims=2048, output_dims=2304, bias=False)\n",
       "        (rope): RoPE(256, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "        (down_proj): Linear(input_dims=9216, output_dims=2304, bias=False)\n",
       "        (up_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "    )\n",
       "    (layers.22): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): Linear(input_dims=2304, output_dims=2048, bias=False)\n",
       "        (k_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (v_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (o_proj): Linear(input_dims=2048, output_dims=2304, bias=False)\n",
       "        (rope): RoPE(256, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "        (down_proj): Linear(input_dims=9216, output_dims=2304, bias=False)\n",
       "        (up_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "    )\n",
       "    (layers.23): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): Linear(input_dims=2304, output_dims=2048, bias=False)\n",
       "        (k_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (v_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (o_proj): Linear(input_dims=2048, output_dims=2304, bias=False)\n",
       "        (rope): RoPE(256, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "        (down_proj): Linear(input_dims=9216, output_dims=2304, bias=False)\n",
       "        (up_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "    )\n",
       "    (layers.24): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): Linear(input_dims=2304, output_dims=2048, bias=False)\n",
       "        (k_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (v_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (o_proj): Linear(input_dims=2048, output_dims=2304, bias=False)\n",
       "        (rope): RoPE(256, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "        (down_proj): Linear(input_dims=9216, output_dims=2304, bias=False)\n",
       "        (up_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "    )\n",
       "    (layers.25): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): Linear(input_dims=2304, output_dims=2048, bias=False)\n",
       "        (k_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (v_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (o_proj): Linear(input_dims=2048, output_dims=2304, bias=False)\n",
       "        (rope): RoPE(256, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "        (down_proj): Linear(input_dims=9216, output_dims=2304, bias=False)\n",
       "        (up_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "    )\n",
       "    (norm): RMSNorm()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d7ca989",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_to_lora_layers(model, lora_config[\"lora_layers\"], lora_config[\"lora_parameters\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6e8a605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters: 491520\n"
     ]
    }
   ],
   "source": [
    "num_train_params = (\n",
    "    sum(v.size for _, v in tree_flatten(model.trainable_parameters()))\n",
    ")\n",
    "print(f\"Number of trainable parameters: {num_train_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f835fb6-9e13-4db6-a03d-419f9a471e32",
   "metadata": {},
   "source": [
    "**Set the optimizer, Build a class to record the data during the training process**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b46a433",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (model): GemmaModel(\n",
       "    (embed_tokens): Embedding(256000, 2304)\n",
       "    (layers.0): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): Linear(input_dims=2304, output_dims=2048, bias=False)\n",
       "        (k_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (v_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (o_proj): Linear(input_dims=2048, output_dims=2304, bias=False)\n",
       "        (rope): RoPE(256, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "        (down_proj): Linear(input_dims=9216, output_dims=2304, bias=False)\n",
       "        (up_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "    )\n",
       "    (layers.1): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): Linear(input_dims=2304, output_dims=2048, bias=False)\n",
       "        (k_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (v_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (o_proj): Linear(input_dims=2048, output_dims=2304, bias=False)\n",
       "        (rope): RoPE(256, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "        (down_proj): Linear(input_dims=9216, output_dims=2304, bias=False)\n",
       "        (up_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "    )\n",
       "    (layers.2): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): Linear(input_dims=2304, output_dims=2048, bias=False)\n",
       "        (k_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (v_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (o_proj): Linear(input_dims=2048, output_dims=2304, bias=False)\n",
       "        (rope): RoPE(256, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "        (down_proj): Linear(input_dims=9216, output_dims=2304, bias=False)\n",
       "        (up_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "    )\n",
       "    (layers.3): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): Linear(input_dims=2304, output_dims=2048, bias=False)\n",
       "        (k_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (v_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (o_proj): Linear(input_dims=2048, output_dims=2304, bias=False)\n",
       "        (rope): RoPE(256, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "        (down_proj): Linear(input_dims=9216, output_dims=2304, bias=False)\n",
       "        (up_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "    )\n",
       "    (layers.4): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): Linear(input_dims=2304, output_dims=2048, bias=False)\n",
       "        (k_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (v_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (o_proj): Linear(input_dims=2048, output_dims=2304, bias=False)\n",
       "        (rope): RoPE(256, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "        (down_proj): Linear(input_dims=9216, output_dims=2304, bias=False)\n",
       "        (up_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "    )\n",
       "    (layers.5): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): Linear(input_dims=2304, output_dims=2048, bias=False)\n",
       "        (k_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (v_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (o_proj): Linear(input_dims=2048, output_dims=2304, bias=False)\n",
       "        (rope): RoPE(256, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "        (down_proj): Linear(input_dims=9216, output_dims=2304, bias=False)\n",
       "        (up_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "    )\n",
       "    (layers.6): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): Linear(input_dims=2304, output_dims=2048, bias=False)\n",
       "        (k_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (v_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (o_proj): Linear(input_dims=2048, output_dims=2304, bias=False)\n",
       "        (rope): RoPE(256, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "        (down_proj): Linear(input_dims=9216, output_dims=2304, bias=False)\n",
       "        (up_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "    )\n",
       "    (layers.7): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): Linear(input_dims=2304, output_dims=2048, bias=False)\n",
       "        (k_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (v_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (o_proj): Linear(input_dims=2048, output_dims=2304, bias=False)\n",
       "        (rope): RoPE(256, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "        (down_proj): Linear(input_dims=9216, output_dims=2304, bias=False)\n",
       "        (up_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "    )\n",
       "    (layers.8): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): Linear(input_dims=2304, output_dims=2048, bias=False)\n",
       "        (k_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (v_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (o_proj): Linear(input_dims=2048, output_dims=2304, bias=False)\n",
       "        (rope): RoPE(256, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "        (down_proj): Linear(input_dims=9216, output_dims=2304, bias=False)\n",
       "        (up_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "    )\n",
       "    (layers.9): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): Linear(input_dims=2304, output_dims=2048, bias=False)\n",
       "        (k_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (v_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (o_proj): Linear(input_dims=2048, output_dims=2304, bias=False)\n",
       "        (rope): RoPE(256, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "        (down_proj): Linear(input_dims=9216, output_dims=2304, bias=False)\n",
       "        (up_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "    )\n",
       "    (layers.10): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): Linear(input_dims=2304, output_dims=2048, bias=False)\n",
       "        (k_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (v_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (o_proj): Linear(input_dims=2048, output_dims=2304, bias=False)\n",
       "        (rope): RoPE(256, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "        (down_proj): Linear(input_dims=9216, output_dims=2304, bias=False)\n",
       "        (up_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "    )\n",
       "    (layers.11): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): Linear(input_dims=2304, output_dims=2048, bias=False)\n",
       "        (k_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (v_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (o_proj): Linear(input_dims=2048, output_dims=2304, bias=False)\n",
       "        (rope): RoPE(256, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "        (down_proj): Linear(input_dims=9216, output_dims=2304, bias=False)\n",
       "        (up_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "    )\n",
       "    (layers.12): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): Linear(input_dims=2304, output_dims=2048, bias=False)\n",
       "        (k_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (v_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (o_proj): Linear(input_dims=2048, output_dims=2304, bias=False)\n",
       "        (rope): RoPE(256, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "        (down_proj): Linear(input_dims=9216, output_dims=2304, bias=False)\n",
       "        (up_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "    )\n",
       "    (layers.13): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): Linear(input_dims=2304, output_dims=2048, bias=False)\n",
       "        (k_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (v_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (o_proj): Linear(input_dims=2048, output_dims=2304, bias=False)\n",
       "        (rope): RoPE(256, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "        (down_proj): Linear(input_dims=9216, output_dims=2304, bias=False)\n",
       "        (up_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "    )\n",
       "    (layers.14): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): Linear(input_dims=2304, output_dims=2048, bias=False)\n",
       "        (k_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (v_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (o_proj): Linear(input_dims=2048, output_dims=2304, bias=False)\n",
       "        (rope): RoPE(256, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "        (down_proj): Linear(input_dims=9216, output_dims=2304, bias=False)\n",
       "        (up_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "    )\n",
       "    (layers.15): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): Linear(input_dims=2304, output_dims=2048, bias=False)\n",
       "        (k_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (v_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (o_proj): Linear(input_dims=2048, output_dims=2304, bias=False)\n",
       "        (rope): RoPE(256, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "        (down_proj): Linear(input_dims=9216, output_dims=2304, bias=False)\n",
       "        (up_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "    )\n",
       "    (layers.16): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): Linear(input_dims=2304, output_dims=2048, bias=False)\n",
       "        (k_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (v_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (o_proj): Linear(input_dims=2048, output_dims=2304, bias=False)\n",
       "        (rope): RoPE(256, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "        (down_proj): Linear(input_dims=9216, output_dims=2304, bias=False)\n",
       "        (up_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "    )\n",
       "    (layers.17): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): Linear(input_dims=2304, output_dims=2048, bias=False)\n",
       "        (k_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (v_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (o_proj): Linear(input_dims=2048, output_dims=2304, bias=False)\n",
       "        (rope): RoPE(256, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "        (down_proj): Linear(input_dims=9216, output_dims=2304, bias=False)\n",
       "        (up_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "    )\n",
       "    (layers.18): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): LoRALinear(\n",
       "          (linear): Linear(input_dims=2304, output_dims=2048, bias=False)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (k_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (v_proj): LoRALinear(\n",
       "          (linear): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (o_proj): Linear(input_dims=2048, output_dims=2304, bias=False)\n",
       "        (rope): RoPE(256, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "        (down_proj): Linear(input_dims=9216, output_dims=2304, bias=False)\n",
       "        (up_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "    )\n",
       "    (layers.19): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): LoRALinear(\n",
       "          (linear): Linear(input_dims=2304, output_dims=2048, bias=False)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (k_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (v_proj): LoRALinear(\n",
       "          (linear): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (o_proj): Linear(input_dims=2048, output_dims=2304, bias=False)\n",
       "        (rope): RoPE(256, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "        (down_proj): Linear(input_dims=9216, output_dims=2304, bias=False)\n",
       "        (up_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "    )\n",
       "    (layers.20): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): LoRALinear(\n",
       "          (linear): Linear(input_dims=2304, output_dims=2048, bias=False)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (k_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (v_proj): LoRALinear(\n",
       "          (linear): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (o_proj): Linear(input_dims=2048, output_dims=2304, bias=False)\n",
       "        (rope): RoPE(256, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "        (down_proj): Linear(input_dims=9216, output_dims=2304, bias=False)\n",
       "        (up_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "    )\n",
       "    (layers.21): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): LoRALinear(\n",
       "          (linear): Linear(input_dims=2304, output_dims=2048, bias=False)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (k_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (v_proj): LoRALinear(\n",
       "          (linear): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (o_proj): Linear(input_dims=2048, output_dims=2304, bias=False)\n",
       "        (rope): RoPE(256, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "        (down_proj): Linear(input_dims=9216, output_dims=2304, bias=False)\n",
       "        (up_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "    )\n",
       "    (layers.22): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): LoRALinear(\n",
       "          (linear): Linear(input_dims=2304, output_dims=2048, bias=False)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (k_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (v_proj): LoRALinear(\n",
       "          (linear): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (o_proj): Linear(input_dims=2048, output_dims=2304, bias=False)\n",
       "        (rope): RoPE(256, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "        (down_proj): Linear(input_dims=9216, output_dims=2304, bias=False)\n",
       "        (up_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "    )\n",
       "    (layers.23): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): LoRALinear(\n",
       "          (linear): Linear(input_dims=2304, output_dims=2048, bias=False)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (k_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (v_proj): LoRALinear(\n",
       "          (linear): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (o_proj): Linear(input_dims=2048, output_dims=2304, bias=False)\n",
       "        (rope): RoPE(256, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "        (down_proj): Linear(input_dims=9216, output_dims=2304, bias=False)\n",
       "        (up_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "    )\n",
       "    (layers.24): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): LoRALinear(\n",
       "          (linear): Linear(input_dims=2304, output_dims=2048, bias=False)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (k_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (v_proj): LoRALinear(\n",
       "          (linear): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (o_proj): Linear(input_dims=2048, output_dims=2304, bias=False)\n",
       "        (rope): RoPE(256, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "        (down_proj): Linear(input_dims=9216, output_dims=2304, bias=False)\n",
       "        (up_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "    )\n",
       "    (layers.25): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): LoRALinear(\n",
       "          (linear): Linear(input_dims=2304, output_dims=2048, bias=False)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (k_proj): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "        (v_proj): LoRALinear(\n",
       "          (linear): Linear(input_dims=2304, output_dims=1024, bias=False)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (o_proj): Linear(input_dims=2048, output_dims=2304, bias=False)\n",
       "        (rope): RoPE(256, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "        (down_proj): Linear(input_dims=9216, output_dims=2304, bias=False)\n",
       "        (up_proj): Linear(input_dims=2304, output_dims=9216, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "    )\n",
       "    (norm): RMSNorm()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fa0e2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(learning_rate=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6884d9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics:\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    def on_train_loss_report(self, info):\n",
    "        self.train_losses.append((info[\"iteration\"], info[\"train_loss\"]))\n",
    "    def on_val_loss_report(self, info):\n",
    "        self.val_losses.append((info[\"iteration\"], info[\"val_loss\"]))\n",
    "        \n",
    "metrics = Metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73070f2-ab2d-4964-8da2-01e1c0d39f0f",
   "metadata": {},
   "source": [
    "**Start Fine-tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36f96568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training..., iters: 200\n",
      "Iter 1: Val loss 3.161, Val took 49.532s\n",
      "Iter 10: Train loss 3.801, Learning Rate 1.000e-05, It/sec 0.513, Tokens/sec 377.133, Trained Tokens 7348, Peak mem 25.797 GB\n",
      "Iter 20: Train loss 3.050, Learning Rate 1.000e-05, It/sec 0.315, Tokens/sec 228.261, Trained Tokens 14605, Peak mem 29.260 GB\n",
      "Iter 30: Train loss 2.622, Learning Rate 1.000e-05, It/sec 0.085, Tokens/sec 103.549, Trained Tokens 26780, Peak mem 37.153 GB\n",
      "Iter 40: Train loss 2.764, Learning Rate 1.000e-05, It/sec 0.326, Tokens/sec 307.783, Trained Tokens 36228, Peak mem 37.153 GB\n",
      "Iter 50: Val loss 2.721, Val took 36.993s\n",
      "Iter 50: Train loss 2.637, Learning Rate 1.000e-05, It/sec 4.204, Tokens/sec 3228.857, Trained Tokens 43909, Peak mem 37.153 GB\n",
      "Iter 60: Train loss 2.554, Learning Rate 1.000e-05, It/sec 0.208, Tokens/sec 188.639, Trained Tokens 52962, Peak mem 37.153 GB\n",
      "Iter 70: Train loss 2.499, Learning Rate 1.000e-05, It/sec 0.527, Tokens/sec 377.368, Trained Tokens 60119, Peak mem 37.153 GB\n",
      "Iter 80: Train loss 2.433, Learning Rate 1.000e-05, It/sec 0.434, Tokens/sec 323.837, Trained Tokens 67581, Peak mem 37.153 GB\n",
      "Iter 90: Train loss 2.507, Learning Rate 1.000e-05, It/sec 0.477, Tokens/sec 321.200, Trained Tokens 74321, Peak mem 37.153 GB\n",
      "Iter 100: Val loss 2.446, Val took 36.340s\n",
      "Iter 100: Train loss 2.607, Learning Rate 1.000e-05, It/sec 6.323, Tokens/sec 6607.638, Trained Tokens 84771, Peak mem 37.153 GB\n",
      "Iter 100: Saved adapter weights to adapters/adapters.safetensors and adapters/0000100_adapters.safetensors.\n",
      "Iter 110: Train loss 2.548, Learning Rate 1.000e-05, It/sec 0.487, Tokens/sec 355.604, Trained Tokens 92080, Peak mem 37.153 GB\n",
      "Iter 120: Train loss 2.345, Learning Rate 1.000e-05, It/sec 0.128, Tokens/sec 119.464, Trained Tokens 101403, Peak mem 38.847 GB\n",
      "Iter 130: Train loss 2.408, Learning Rate 1.000e-05, It/sec 0.048, Tokens/sec 68.830, Trained Tokens 115870, Peak mem 46.745 GB\n",
      "Iter 140: Train loss 2.370, Learning Rate 1.000e-05, It/sec 0.172, Tokens/sec 165.129, Trained Tokens 125494, Peak mem 46.745 GB\n",
      "Iter 150: Val loss 2.442, Val took 41.837s\n",
      "Iter 150: Train loss 2.404, Learning Rate 1.000e-05, It/sec 4.565, Tokens/sec 2828.665, Trained Tokens 131691, Peak mem 46.745 GB\n",
      "Iter 160: Train loss 2.242, Learning Rate 1.000e-05, It/sec 0.505, Tokens/sec 354.544, Trained Tokens 138706, Peak mem 46.745 GB\n",
      "Iter 170: Train loss 2.136, Learning Rate 1.000e-05, It/sec 0.519, Tokens/sec 332.589, Trained Tokens 145116, Peak mem 46.745 GB\n",
      "Iter 180: Train loss 2.485, Learning Rate 1.000e-05, It/sec 0.605, Tokens/sec 375.627, Trained Tokens 151323, Peak mem 46.745 GB\n",
      "Iter 190: Train loss 2.317, Learning Rate 1.000e-05, It/sec 0.515, Tokens/sec 361.793, Trained Tokens 158349, Peak mem 46.745 GB\n",
      "Iter 200: Val loss 2.438, Val took 27.621s\n",
      "Iter 200: Train loss 2.453, Learning Rate 1.000e-05, It/sec 6.608, Tokens/sec 6626.117, Trained Tokens 168377, Peak mem 46.745 GB\n",
      "Iter 200: Saved adapter weights to adapters/adapters.safetensors and adapters/0000200_adapters.safetensors.\n",
      "Saved final adapter weights to adapters/adapters.safetensors.\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    args = training_args,\n",
    "    optimizer = opt,\n",
    "    train_dataset = train_set,\n",
    "    val_dataset = dev_set,\n",
    "    training_callback = metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40dfa067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_its, train_losses = zip(*metrics.train_losses)\n",
    "val_its, val_losses = zip(*metrics.val_losses)\n",
    "plt.plot(train_its, train_losses, '-o')\n",
    "plt.plot(val_its, val_losses, '-o')\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(['Train', \"Valid\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b716e28f-b623-484d-87a8-d840cbf0c049",
   "metadata": {},
   "source": [
    "## Use the parameters from the original model and adapter file to build the LoRA model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eca835ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lora, _ = load(\"google/gemma-2-2b-it\", adapter_path=\"adapters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7dbce846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "Prompt: <bos><start_of_turn>user\n",
      "What is under-fitting and overfitting in machine learning?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "\n",
      "Underfitting and overfitting are two common problems in machine learning that can affect the performance of a model.<end_of_turn>\n",
      "==========\n",
      "Prompt: 22 tokens, 9.266 tokens-per-sec\n",
      "Generation: 23 tokens, 11.483 tokens-per-sec\n",
      "Peak memory: 46.745 GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Underfitting and overfitting are two common problems in machine learning that can affect the performance of a model.<end_of_turn>'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(model_lora, tokenizer, prompt=prompt, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5709c039-2654-43b8-9707-a0e929440e3e",
   "metadata": {},
   "source": [
    "## Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "298c3bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model\r\n"
     ]
    }
   ],
   "source": [
    "!mlx_lm.fuse --model \"google/gemma-2-2b-it\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
